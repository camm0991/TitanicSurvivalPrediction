{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanica Survival prediction\n",
    "<br/>\n",
    "Based on the tutorial made by [Patrick Triest](http://www.kdnuggets.com/2016/07/titanic-machine-learning-guide-part-1.html)\n",
    "<br/><br/>\n",
    "In this jupyter notebook we are going to follow the tutorial made by Patrick Triest but adding a feature selection algorithm.\n",
    "<br/><br/>\n",
    "By Carlos Martinez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from sklearn import datasets, svm, tree, preprocessing\n",
    "from sklearn.base import clone\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow.contrib import learn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sklearn.ensemble as ske\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SBS algorithm for feature selection\n",
    "Code implementation taken from the book Python machine learning by Sebastian Raschka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SBS():\n",
    "    def __init__(self, estimator, k_features, \n",
    "        scoring=accuracy_score,\n",
    "        test_size=0.25, random_state=1):\n",
    "        self.scoring = scoring\n",
    "        self.estimator = clone(estimator)\n",
    "        self.k_features = k_features\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                            test_size=self.test_size,\n",
    "                                                            random_state=self.random_state)\n",
    "\n",
    "        dim = X_train.shape[1]\n",
    "        self.indices_ = tuple(range(dim))\n",
    "        self.subsets_ = [self.indices_]\n",
    "        score = self._calc_score(X_train, y_train, \n",
    "                                 X_test, y_test, self.indices_)\n",
    "        self.scores_ = [score]\n",
    "\n",
    "        while dim > self.k_features:\n",
    "            scores = []\n",
    "            subsets = []\n",
    "\n",
    "            for p in combinations(self.indices_, r=dim-1):\n",
    "                score = self._calc_score(X_train, y_train, \n",
    "                                         X_test, y_test, p)\n",
    "                scores.append(score)\n",
    "                subsets.append(p)\n",
    "\n",
    "            best = np.argmax(scores)\n",
    "            self.indices_ = subsets[best]\n",
    "            self.subsets_.append(self.indices_)\n",
    "            dim -= 1\n",
    "\n",
    "            self.scores_.append(scores[best])\n",
    "        self.k_score_ = self.scores_[-1]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[:, self.indices_]\n",
    "\n",
    "    def _calc_score(self, X_train, y_train, \n",
    "                          X_test, y_test, indices):\n",
    "        self.estimator.fit(X_train[:, indices], y_train)\n",
    "        y_pred = self.estimator.predict(X_test[:, indices])\n",
    "        score = self.scoring(y_test, y_pred)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic dataset\n",
    "Dataset source: [Biostat titanic dataset](http://biostat.mc.vanderbilt.edu/wiki/Main/DataSets/titanic3.xls)\n",
    "<br/>\n",
    "This dataset contains the information of 1308 passangers and contains the following labels:\n",
    "\n",
    "* pclass    -> Passenger class (1st, 2nd and 3rd).\n",
    "* survived  -> If the passenger survived (0 = No, 1 = Yes).\n",
    "* name      -> Passenger's name.\n",
    "* sex       -> Passenger's gender (0 = Female, 1 = Male).\n",
    "* age       -> Passenger's age.\n",
    "* sibsp     -> Number of siblings and/or spouses aboard.\n",
    "* parch     -> Number of parents and/or children aboard.\n",
    "* ticket    -> Ticket number.\n",
    "* fare      -> Passenger fare.\n",
    "* cabin     -> Cabin number.\n",
    "* embarked  -> Where does the passenger embarked (Cherbourg, Queenstown or Southhampton).\n",
    "* boat      -> Number of lifeboat, if survided, the passenger where embarked on.\n",
    "* body      -> Body number, assigned if the body was recovered.\n",
    "* home.dest -> Coming from / going to locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and looking at the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "       age  sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
       "0  29.0000      0      0   24160  211.3375       B5        S    2    NaN   \n",
       "1   0.9167      1      2  113781  151.5500  C22 C26        S   11    NaN   \n",
       "2   2.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "3  30.0000      1      2  113781  151.5500  C22 C26        S  NaN  135.0   \n",
       "4  25.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df = pd.read_excel('titanic3.xls', 'titanic3', index__col=None, na_values=['NA'])\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining some information from the dataset\n",
    "<br/>\n",
    "Here we are going to look at some dataset statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3819709702062643"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df['survived'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The survival rate was very low generaly speaking, like nearly four of every ten passengers survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.619195</td>\n",
       "      <td>39.159918</td>\n",
       "      <td>0.436533</td>\n",
       "      <td>0.365325</td>\n",
       "      <td>87.508992</td>\n",
       "      <td>162.828571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.429603</td>\n",
       "      <td>29.506705</td>\n",
       "      <td>0.393502</td>\n",
       "      <td>0.368231</td>\n",
       "      <td>21.179196</td>\n",
       "      <td>167.387097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.255289</td>\n",
       "      <td>24.816367</td>\n",
       "      <td>0.568406</td>\n",
       "      <td>0.400564</td>\n",
       "      <td>13.302889</td>\n",
       "      <td>155.818182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        survived        age     sibsp     parch       fare        body\n",
       "pclass                                                                \n",
       "1       0.619195  39.159918  0.436533  0.365325  87.508992  162.828571\n",
       "2       0.429603  29.506705  0.393502  0.368231  21.179196  167.387097\n",
       "3       0.255289  24.816367  0.568406  0.400564  13.302889  155.818182"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.groupby('pclass').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now grouping by passenger class we can see that the one with the highest survival rate was the first class and the lowest was the third class, that's understandable because of their rigth to a lifeboat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>female</th>\n",
       "      <td>0.965278</td>\n",
       "      <td>37.037594</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>109.412385</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.340782</td>\n",
       "      <td>41.029250</td>\n",
       "      <td>0.340782</td>\n",
       "      <td>0.279330</td>\n",
       "      <td>69.888385</td>\n",
       "      <td>162.828571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>female</th>\n",
       "      <td>0.886792</td>\n",
       "      <td>27.499191</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.650943</td>\n",
       "      <td>23.234827</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.146199</td>\n",
       "      <td>30.815401</td>\n",
       "      <td>0.327485</td>\n",
       "      <td>0.192982</td>\n",
       "      <td>19.904946</td>\n",
       "      <td>171.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>female</th>\n",
       "      <td>0.490741</td>\n",
       "      <td>22.185307</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.731481</td>\n",
       "      <td>15.324250</td>\n",
       "      <td>183.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.152130</td>\n",
       "      <td>25.962273</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.255578</td>\n",
       "      <td>12.415462</td>\n",
       "      <td>151.854167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               survived        age     sibsp     parch        fare        body\n",
       "pclass sex                                                                    \n",
       "1      female  0.965278  37.037594  0.555556  0.472222  109.412385         NaN\n",
       "       male    0.340782  41.029250  0.340782  0.279330   69.888385  162.828571\n",
       "2      female  0.886792  27.499191  0.500000  0.650943   23.234827   52.000000\n",
       "       male    0.146199  30.815401  0.327485  0.192982   19.904946  171.233333\n",
       "3      female  0.490741  22.185307  0.791667  0.731481   15.324250  183.000000\n",
       "       male    0.152130  25.962273  0.470588  0.255578   12.415462  151.854167"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_sex_grouping = titanic_df.groupby(['pclass','sex']).mean()\n",
    "class_sex_grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping by class and sex we can see that nearly all of the first class female passengers survived, something similar for the second class but the third did'nt run with that luck. We can also observe that the men had a bad time, that can be said because the survival rate of any of the mens classes population had more than 35 percent survival rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminating probable useless attributes and rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass       1309\n",
       "survived     1309\n",
       "name         1309\n",
       "sex          1309\n",
       "age          1046\n",
       "sibsp        1309\n",
       "parch        1309\n",
       "ticket       1309\n",
       "fare         1308\n",
       "cabin         295\n",
       "embarked     1307\n",
       "boat          486\n",
       "body          121\n",
       "home.dest     745\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the labes boat, body and cabin have a lot of missing values.\n",
    "<br/>\n",
    "* The cabin number could be relevant because the proximity to a lifeboat but unfortunately there a too many missing values so it can be discarded.\n",
    "* The boat number is not relevant because who cares if the passenger was aboard the lifeboat number twenty.\n",
    "* The body number is not useful because if the passenger have one that means that they did not survived.\n",
    "\n",
    "We also see that other information that migth not be relevant can be from the labels name, ticket and home/dest.\n",
    "Maybe only the name because the passanger could be an influential person but that would require additional information about the person.\n",
    "<br/>\n",
    "So we are going to drop all of these attributes and delete the rows with missing values, with that we're going to have a dataset full of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass      1043\n",
       "survived    1043\n",
       "sex         1043\n",
       "age         1043\n",
       "sibsp       1043\n",
       "parch       1043\n",
       "fare        1043\n",
       "embarked    1043\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df = titanic_df.drop(['boat', 'body', 'cabin', 'home.dest', 'name', 'ticket'], axis=1)\n",
    "titanic_df = titanic_df.dropna()\n",
    "titanic_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 1043 records to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we take a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived     sex      age  sibsp  parch      fare embarked\n",
       "0       1         1  female  29.0000      0      0  211.3375        S\n",
       "1       1         1    male   0.9167      1      2  151.5500        S\n",
       "2       1         0  female   2.0000      1      2  151.5500        S\n",
       "3       1         0    male  30.0000      1      2  151.5500        S\n",
       "4       1         0  female  25.0000      1      2  151.5500        S"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels sex and embarked must be encoded so the learning algorithms does'nt have a bad time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived  sex      age  sibsp  parch      fare  embarked\n",
       "0       1         1    0  29.0000      0      0  211.3375         2\n",
       "1       1         1    1   0.9167      1      2  151.5500         2\n",
       "2       1         0    0   2.0000      1      2  151.5500         2\n",
       "3       1         0    1  30.0000      1      2  151.5500         2\n",
       "4       1         0    0  25.0000      1      2  151.5500         2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "titanic_df.sex = label_encoder.fit_transform(titanic_df.sex)\n",
    "titanic_df.embarked = label_encoder.fit_transform(titanic_df.embarked)\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is nearly ready, we may now apply a feature selection algorithm to see if we can discard another attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Creating the standarized training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = titanic_df.drop(['survived'], axis=1).values, titanic_df['survived'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "stdsc = preprocessing.StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now we are ready for the feature selection process using the standarized dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the algorithm declared at the beginning of the notebook to see which of the attributes are the most relevant according to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  sex      age  sibsp  parch      fare  embarked\n",
       "0       1    0  29.0000      0      0  211.3375         2\n",
       "1       1    1   0.9167      1      2  151.5500         2\n",
       "2       1    0   2.0000      1      2  151.5500         2\n",
       "3       1    1  30.0000      1      2  151.5500         2\n",
       "4       1    0  25.0000      1      2  151.5500         2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.drop(['survived'], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAF5CAYAAACiFUGDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f28e5178438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "sbs = SBS(knn, k_features=1)\n",
    "sbs.fit(X_train_std, y_train)\n",
    "\n",
    "k_feat = [len(k) for k in sbs.subsets_]\n",
    "\n",
    "#Showing the results\n",
    "plt.plot(k_feat, sbs.scores_, marker='o')\n",
    "plt.ylim([0.7, 1.1])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of features')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this results the best score is obtained when three features are used but in this case we are going to use the features from the best and the second best accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare'], dtype='object')\n",
      "Index(['pclass', 'sex', 'age', 'sibsp', 'parch'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "k6 = list(sbs.subsets_[1])\n",
    "k5 = list(sbs.subsets_[2])\n",
    "print(titanic_df.drop(['survived'], axis=1).columns[0:][k6])\n",
    "print(titanic_df.drop(['survived'], axis=1).columns[0:][k5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the attribute that is discarded in both cases is embarked and the one eliminated in k5 is also fare, now we need to test some classifiers using all the attributes and the ones given by the algorithm to make a comparison between the three."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the new datasets and the scoring function\n",
    "<br/>\n",
    "We already have ourt test and train datasets but now we need to create the ones with the selected features, here X_train and X_test will be the original ones while X_fs_5 and X_fs_6 will have less features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train and X_test already exist\n",
    "stdsc = preprocessing.StandardScaler()\n",
    "#For 6 features\n",
    "X_fs_6, y_fs_6 = titanic_df.drop(['survived','embarked'], axis=1).values, titanic_df['survived'].values\n",
    "X_fs_6_train, X_fs_6_test, y_fs_6_train, y_fs_6_test = train_test_split(X_fs_6, y_fs_6, test_size=0.3, random_state=42)\n",
    "\n",
    "X_fs_6_train_std = stdsc.fit_transform(X_fs_6_train)\n",
    "X_fs_6_test_std = stdsc.transform(X_fs_6_test)\n",
    "#For 5 features\n",
    "X_fs_5, y_fs_5 = titanic_df.drop(['survived', 'fare','embarked'], axis=1).values, titanic_df['survived'].values\n",
    "X_fs_5_train, X_fs_5_test, y_fs_5_train, y_fs_5_test = train_test_split(X_fs_5, y_fs_5, test_size=0.3, random_state=42)\n",
    "\n",
    "X_fs_5_train_std = stdsc.fit_transform(X_fs_5_train)\n",
    "X_fs_5_test_std = stdsc.transform(X_fs_5_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_classifier(classifier):\n",
    "    classifier.fit(X_train_std, y_train)\n",
    "    print('Without feature selection')\n",
    "    print('Train accuracy: {:.5f}'.format(classifier.score(X_train_std, y_train)))\n",
    "    print('Test accuracy: {:.5f}\\n'.format(classifier.score(X_test_std, y_test)))\n",
    "    \n",
    "    classifier.fit(X_fs_6_train_std, y_fs_6_train)\n",
    "    print('With feature selection (6 features)')\n",
    "    print('Train accuracy: {:.5f}'.format(classifier.score(X_fs_6_train_std, y_fs_6_train)))\n",
    "    print('Test accuracy: {:.5f}\\n'.format(classifier.score(X_fs_6_test_std, y_fs_6_test)))\n",
    "    \n",
    "    classifier.fit(X_fs_5_train_std, y_fs_5_train)\n",
    "    print('With feature selection (5 features)')\n",
    "    print('Train accuracy: {:.5f}'.format(classifier.score(X_fs_5_train_std, y_fs_5_train)))\n",
    "    print('Test accuracy: {:.5f}'.format(classifier.score(X_fs_5_test_std, y_fs_5_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Science Kit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without feature selection\n",
      "Train accuracy: 0.82877\n",
      "Test accuracy: 0.78594\n",
      "\n",
      "With feature selection (6 features)\n",
      "Train accuracy: 0.82877\n",
      "Test accuracy: 0.78594\n",
      "\n",
      "With feature selection (5 features)\n",
      "Train accuracy: 0.81781\n",
      "Test accuracy: 0.77955\n"
     ]
    }
   ],
   "source": [
    "clf_dt = tree.DecisionTreeClassifier(max_depth=3)\n",
    "test_classifier(clf_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without feature selection\n",
      "Train accuracy: 0.98493\n",
      "Test accuracy: 0.74121\n",
      "\n",
      "With feature selection (6 features)\n",
      "Train accuracy: 0.98356\n",
      "Test accuracy: 0.73802\n",
      "\n",
      "With feature selection (5 features)\n",
      "Train accuracy: 0.92329\n",
      "Test accuracy: 0.75719\n"
     ]
    }
   ],
   "source": [
    "clf_rf = ske.RandomForestClassifier(n_estimators=50)\n",
    "test_classifier(clf_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without feature selection\n",
      "Train accuracy: 0.86575\n",
      "Test accuracy: 0.78275\n",
      "\n",
      "With feature selection (6 features)\n",
      "Train accuracy: 0.86575\n",
      "Test accuracy: 0.79233\n",
      "\n",
      "With feature selection (5 features)\n",
      "Train accuracy: 0.85616\n",
      "Test accuracy: 0.79233\n"
     ]
    }
   ],
   "source": [
    "clf_gb = ske.GradientBoostingClassifier(n_estimators=50)\n",
    "test_classifier(clf_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without feature selection\n",
      "Train accuracy: 0.87397\n",
      "Test accuracy: 0.78275\n",
      "\n",
      "With feature selection (6 features)\n",
      "Train accuracy: 0.87808\n",
      "Test accuracy: 0.78594\n",
      "\n",
      "With feature selection (5 features)\n",
      "Train accuracy: 0.86849\n",
      "Test accuracy: 0.79553\n"
     ]
    }
   ],
   "source": [
    "clf_vc = ske.VotingClassifier([('dt', clf_dt), ('rf', clf_rf), ('gb', clf_gb)])\n",
    "test_classifier(clf_vc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the best option is to use a voting classifier because it takes in account all of the classifiers and uses a 'democratic' system in which all the votants are 'persons' that know abbout the topic. For this cases using less fatures yield better results according to the SBS prediction except for the decision tree classifier that broke this rule. In this specific case, the best option is to use a voting classifier with 5 features. Now we will use a neural network to test our results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks\n",
    "Now we are going to test the three cases using a simple neural network from the tensor flow library based on the example given by [Illia Polosukhin](https://medium.com/@ilblackdragon/tensorflow-tutorial-part-2-9ffe47049c92#.5joy6sv88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp7ra_zjv9\n",
      "WARNING:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(7)]), is_sparse=False)\n",
      "WARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without feature selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpblvvh8ac\n",
      "WARNING:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(6)]), is_sparse=False)\n",
      "WARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.83151\n",
      "Test accuracy: 0.76358\n",
      "\n",
      "With feature selection (6 features)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpuh0dfgwl\n",
      "WARNING:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(5)]), is_sparse=False)\n",
      "WARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.83425\n",
      "Test accuracy: 0.75080\n",
      "\n",
      "With feature selection (5 features)\n",
      "Train accuracy: 0.83014\n",
      "Test accuracy: 0.76038\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('Without feature selection')\n",
    "classifier = learn.DNNClassifier(hidden_units=[10, 20, 10],\n",
    "                                 n_classes=2,\n",
    "                                 feature_columns=learn.infer_real_valued_columns_from_input(X_train_std),\n",
    "                                 optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.05))\n",
    "\n",
    "classifier.fit(X_train_std, y_train, batch_size=128, steps=500)\n",
    "print(\"Train accuracy: {:.5f}\".format(accuracy_score(classifier.predict(X_train_std), y_train)))\n",
    "print(\"Test accuracy: {:.5f}\\n\".format(accuracy_score(classifier.predict(X_test_std), y_test)))\n",
    "\n",
    "print('With feature selection (6 features)')\n",
    "classifier_6 = learn.DNNClassifier(hidden_units=[10, 20, 10],\n",
    "                                 n_classes=2,\n",
    "                                 feature_columns=learn.infer_real_valued_columns_from_input(X_fs_6_train_std),\n",
    "                                 optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.05))\n",
    "classifier_6.fit(X_fs_6_train_std, y_fs_6_train, batch_size=128, steps=500)\n",
    "print(\"Train accuracy: {:.5f}\".format(accuracy_score(classifier_6.predict(X_fs_6_train_std), y_fs_6_train)))\n",
    "print(\"Test accuracy: {:.5f}\\n\".format(accuracy_score(classifier_6.predict(X_fs_6_test_std), y_fs_6_test)))\n",
    "\n",
    "print('With feature selection (5 features)')\n",
    "classifier_5 = learn.DNNClassifier(hidden_units=[10, 20, 10],\n",
    "                                 n_classes=2,\n",
    "                                 feature_columns=learn.infer_real_valued_columns_from_input(X_fs_5_train_std),\n",
    "                                 optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.05))\n",
    "classifier_5.fit(X_fs_5_train_std, y_fs_5_train, batch_size=128, steps=500)\n",
    "print(\"Train accuracy: {:.5f}\".format(accuracy_score(classifier_5.predict(X_fs_5_train_std), y_fs_5_train)))\n",
    "print(\"Test accuracy: {:.5f}\".format(accuracy_score(classifier_5.predict(X_fs_5_test_std), y_fs_5_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we see that the neural network with the best test score was the one that used all of the features and the second best was the one that used 5 so maybe using all features except fare would give a better score. In general the neural network approach was only better in testing results than the random forest algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Conclusion\n",
    "<br/>\n",
    "This dataset is interesting because it comes from a real world event in which we can see that the policy 'women and children first' has a meaning also it allows new machine learning users to see some preprocessing tasks like discard features by hand (in this case the elimination of some features are obvious like the 'body nuumber'), deleting rows with missing values, encoding labels and using a feature selection algorithm for reducing the problem dimension. From all of the classifiers the best was (not taking into account the voting one) the gradient boost and the worst was the random forest considering the random state for test and train split with a value of 42, using another random state would give different performance values and other results in the feature selection task.\n",
    "If whe create a hypotetical passenger and we use the voting classifier we will have a 79.55% of confidence of the fate given by the classifier."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Machine Learning kernel",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
